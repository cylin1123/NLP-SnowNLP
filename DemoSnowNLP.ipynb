{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自然语言处理(NLP)是电脑科学，人工智能，语言学关注电脑和人类(自然)语言之间的相互作用的领域。因此，自然语言处理是与人机交互的领域有关的。在自然语言处理面临很多挑战，包括自然语言理解，因此，自然语言处理涉及人机交互的面积。在NLP诸多挑战涉及自然语言理解，即电脑源于人为或自然语言输入的意思，和其他涉及到自然语言生成。现代NLP算法是基于机器学习，特别是统计机器学习。机器学习范式是不同于一般之前的尝试语言处理。语言处理任务的实现，通常涉及直接用手的大套规则编码。\n",
      "许多不同类的机器学习算法已应用于自然语言处理任务。这些算法的输入是一大组从输入资料生成的\"特征\"。一些最早使用的算法，如决策树，产生硬的if-then规则类似于手写的规则，是再普通的系统体系。然而，越来越多的研究集中于统计模型，这使得基于附加实数值的权重，每个输入要素柔软，概率的决策。此类模型具有能够表达许多不同的可能的答案，而不是只有一个相对的确定性，产生更可靠的结果时，这种模型被包括作为较大系统的一个组成部分的优点。自然语言处理研究逐渐从词汇语义成分的语义转移，进一步的，叙事的理解。然而人类水准的自然语言处理，是一个人工智能完全问题。它是相当于解决中央的人工智能问题使电脑和人一样聪明，或强大的AI。自然语言处理的未来一般也因此密切结合人工智能发展。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from snownlp import SnowNLP\n",
    "\n",
    "text =u'''自然語言處理(NLP)是電腦科學，人工智慧，語言學關注電腦和人類(自然)語言之間的相互作用的領域。因此，自然語言處理是與人機交互的領域有關的。在自然語言處理面臨很多挑戰，包括自然語言理解，因此，自然語言處理涉及人機交互的面積。在NLP諸多挑戰涉及自然語言理解，即電腦源于人為或自然語言輸入的意思，和其他涉及到自然語言生成。現代NLP演算法是基於機器學習，特別是統計機器學習。機器學習范式是不同於一般之前的嘗試語言處理。語言處理任務的實現，通常涉及直接用手的大套規則編碼。\n",
    "許多不同類的機器學習演算法已應用于自然語言處理任務。這些演算法的輸入是一大組從輸入資料生成的\"特徵\"。一些最早使用的演算法，如決策樹，產生硬的if-then規則類似於手寫的規則，是再普通的系統體系。然而，越來越多的研究集中於統計模型，這使得基於附加實數值的權重，每個輸入要素柔軟，概率的決策。此類模型具有能夠表達許多不同的可能的答案，而不是只有一個相對的確定性，產生更可靠的結果時，這種模型被包括作為較大系統的一個組成部分的優點。自然語言處理研究逐漸從詞彙語義成分的語義轉移，進一步的，敘事的理解。然而人類水準的自然語言處理，是一個人工智慧完全問題。它是相當於解決中央的人工智慧問題使電腦和人一樣聰明，或強大的AI。自然語言處理的未來一般也因此密切結合人工智慧發展。\n",
    "'''\n",
    "s = SnowNLP(text)\n",
    "\n",
    "#繁體轉簡體\n",
    "print s.han   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自然\n",
      "語言\n",
      "理\n",
      "處\n",
      "類\n",
      "學\n",
      "不\n",
      "人工\n",
      "從\n",
      "算法\n"
     ]
    }
   ],
   "source": [
    "#提取文章關鍵字\n",
    "keywords = s.keywords(10)\n",
    "for item in keywords :\n",
    "    print item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "然而人類水準的自然語言處理\n",
      "語言學關注電腦和人類(自然)語言之間的相互作用的領域\n",
      "自然語言處理的未來一般也因此密切結合人工智慧發展\n",
      "機器學習范式是不同於一般之前的嘗試語言處理\n",
      "自然語言處理(NLP)是電腦科學\n",
      "許多不同類的機器學習演算法已應用于自然語言處理任務\n",
      "在NLP諸多挑戰涉及自然語言理解\n",
      "自然語言處理涉及人機交互的面積\n",
      "包括自然語言理解\n",
      "即電腦源于人為或自然語言輸入的意思\n"
     ]
    }
   ],
   "source": [
    "#提取文章關鍵字\n",
    "summary = s.summary(10)\n",
    "\n",
    "for item in summary:\n",
    "    print item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自然語言處理(NLP)是電腦科學\n",
      "人工智慧\n",
      "語言學關注電腦和人類(自然)語言之間的相互作用的領域\n",
      "因此\n",
      "自然語言處理是與人機交互的領域有關的\n",
      "在自然語言處理面臨很多挑戰\n",
      "包括自然語言理解\n",
      "因此\n",
      "自然語言處理涉及人機交互的面積\n",
      "在NLP諸多挑戰涉及自然語言理解\n",
      "即電腦源于人為或自然語言輸入的意思\n",
      "和其他涉及到自然語言生成\n",
      "現代NLP演算法是基於機器學習\n",
      "特別是統計機器學習\n",
      "機器學習范式是不同於一般之前的嘗試語言處理\n",
      "語言處理任務的實現\n",
      "通常涉及直接用手的大套規則編碼\n",
      "許多不同類的機器學習演算法已應用于自然語言處理任務\n",
      "這些演算法的輸入是一大組從輸入資料生成的\"特徵\"\n",
      "一些最早使用的演算法\n",
      "如決策樹\n",
      "產生硬的if-then規則類似於手寫的規則\n",
      "是再普通的系統體系\n",
      "然而\n",
      "越來越多的研究集中於統計模型\n",
      "這使得基於附加實數值的權重\n",
      "每個輸入要素柔軟\n",
      "概率的決策\n",
      "此類模型具有能夠表達許多不同的可能的答案\n",
      "而不是只有一個相對的確定性\n",
      "產生更可靠的結果時\n",
      "這種模型被包括作為較大系統的一個組成部分的優點\n",
      "自然語言處理研究逐漸從詞彙語義成分的語義轉移\n",
      "進一步的\n",
      "敘事的理解\n",
      "然而人類水準的自然語言處理\n",
      "是一個人工智慧完全問題\n",
      "它是相當於解決中央的人工智慧問題使電腦和人一樣聰明\n",
      "或強大的AI\n",
      "自然語言處理的未來一般也因此密切結合人工智慧發展\n"
     ]
    }
   ],
   "source": [
    "#切分为句子\n",
    "for item in s.sentences :\n",
    "    print item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "情緒情向：0.0321724351314 \n"
     ]
    }
   ],
   "source": [
    "##情感分析 ex1\n",
    "from snownlp import SnowNLP\n",
    "content=u'这是我觉得北京最为名不符实的景点。明明是一个名胜古迹，但是古建筑保护得非常糟糕，感觉公园的价值却已经退化为一个单纯的街心公园，颇有几分管理不善的感觉。不建议外地人去参观。而且售票员和景区工作人员服务态度也很一般，感觉都是爱理不理的样子，真是令人不爽！'\n",
    "s = SnowNLP(content)\n",
    "print(\"情緒情向：%s \" % s.sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "情緒情向：0.999961257042 \n"
     ]
    }
   ],
   "source": [
    "#情感分析 ex2\n",
    "from snownlp import SnowNLP\n",
    "content=u'多年之前，曾到过桂林的象鼻山，为大自然的神奇造化所折服。今年的5月9日，在蒙蒙细雨之中游览了平谷老象峰景区。没有想到，咱北京也有神象峰，体量比象鼻山更大，气势也更加雄伟，而且还是母子双象同体。'\n",
    "s = SnowNLP(content)\n",
    "print(\"情緒情向：%s \" % s.sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "情緒情向：0.29328584172 \n"
     ]
    }
   ],
   "source": [
    "#情感分析 ex3\n",
    "from snownlp import SnowNLP\n",
    "content=u'你是大笨蛋,豬頭'\n",
    "s = SnowNLP(content)\n",
    "print(\"情緒情向：%s \" % s.sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "情緒情向：0.999948797541 \n"
     ]
    }
   ],
   "source": [
    "#情感分析 ex4\n",
    "content = SnowNLP(u'宝贝真的很不错，，这是我第二次买了，我的朋友都好喜欢，穿上特别漂亮！好性感！质量好好！大爱！')\n",
    "content.sentiments\n",
    "print(\"情緒情向：%s \" % content.sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'\\u5b9d': 1}, {u'\\u8d1d': 1}, {u'\\u771f': 1}, {u'\\u7684': 1}, {u'\\u5f88': 1}, {u'\\u4e0d': 1}, {u'\\u9519': 1}, {u'\\uff0c': 1}, {u'\\uff0c': 1}, {u'\\u8fd9': 1}, {u'\\u662f': 1}, {u'\\u6211': 1}, {u'\\u7b2c': 1}, {u'\\u4e8c': 1}, {u'\\u6b21': 1}, {u'\\u4e70': 1}, {u'\\u4e86': 1}, {u'\\uff0c': 1}, {u'\\u6211': 1}, {u'\\u7684': 1}, {u'\\u670b': 1}, {u'\\u53cb': 1}, {u'\\u90fd': 1}, {u'\\u597d': 1}, {u'\\u559c': 1}, {u'\\u6b22': 1}, {u'\\uff0c': 1}, {u'\\u7a7f': 1}, {u'\\u4e0a': 1}, {u'\\u7279': 1}, {u'\\u522b': 1}, {u'\\u6f02': 1}, {u'\\u4eae': 1}, {u'\\uff01': 1}, {u'\\u597d': 1}, {u'\\u6027': 1}, {u'\\u611f': 1}, {u'\\uff01': 1}, {u'\\u8d28': 1}, {u'\\u91cf': 1}, {u'\\u597d': 1}, {u'\\u597d': 1}, {u'\\uff01': 1}, {u'\\u5927': 1}, {u'\\u7231': 1}, {u'\\uff01': 1}]\n",
      "{u'\\uff01': 2.245426679154097, u'\\u6f02': 3.4122472178487406, u'\\u7684': 2.8791984572980396, u'\\u4e86': 3.4122472178487406, u'\\u5f88': 3.4122472178487406, u'\\u670b': 3.4122472178487406, u'\\u4e0a': 3.4122472178487406, u'\\u4e0d': 3.4122472178487406, u'\\uff0c': 2.245426679154097, u'\\u6211': 2.8791984572980396, u'\\u9519': 3.4122472178487406, u'\\u8d1d': 3.4122472178487406, u'\\u559c': 3.4122472178487406, u'\\u771f': 3.4122472178487406, u'\\u6b21': 3.4122472178487406, u'\\u6b22': 3.4122472178487406, u'\\u6027': 3.4122472178487406, u'\\u5b9d': 3.4122472178487406, u'\\u522b': 3.4122472178487406, u'\\u7b2c': 3.4122472178487406, u'\\u662f': 3.4122472178487406, u'\\u4eae': 3.4122472178487406, u'\\u7231': 3.4122472178487406, u'\\u611f': 3.4122472178487406, u'\\u53cb': 3.4122472178487406, u'\\u91cf': 3.4122472178487406, u'\\u4e8c': 3.4122472178487406, u'\\u8fd9': 3.4122472178487406, u'\\u5927': 3.4122472178487406, u'\\u90fd': 3.4122472178487406, u'\\u4e70': 3.4122472178487406, u'\\u8d28': 3.4122472178487406, u'\\u7279': 3.4122472178487406, u'\\u597d': 2.245426679154097, u'\\u7a7f': 3.4122472178487406}\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "content = SnowNLP(u'宝贝真的很不错，，这是我第二次买了，我的朋友都好喜欢，穿上特别漂亮！好性感！质量好好！大爱！')\n",
    "print content.tf\n",
    "print content.idf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.36375376932023024, -0.25882479740093306, 0, 0, -0.30244695426625884]\n",
      "[0, 0, 1.4896437812448946, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "text = [\n",
    "    [u'性格', u'温柔'],\n",
    "    [u'善良', u'温柔', u'美丽', u'善良'],\n",
    "    [u'好人'],\n",
    "    [u'善良', u'善良'],\n",
    "    [u'美丽', u'性格', u'温柔']\n",
    "]\n",
    "s = SnowNLP(text)\n",
    "print(s.sim([u'温柔']))\n",
    "print(s.sim([u'好人']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.466337068793427, 1.5769147207285403, 1.5769147207285403, 1.466337068793427, 1.466337068793427, 1.466337068793427, 1.466337068793427]\n",
      "[0, 0, 0, 0, 0, 0, 1.466337068793427]\n"
     ]
    }
   ],
   "source": [
    "#文本相似性計算\n",
    "text = u'今天天氣非常好'\n",
    "s = SnowNLP(text)\n",
    "print(s.sim(u'今天天氣非常不好'))\n",
    "print(s.sim(u'好人'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
